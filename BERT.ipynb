{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25145,"status":"ok","timestamp":1667788021242,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"pd5GN5pzgpQI","outputId":"2d768cc8-74c2-44d0-913d-3a7d207b6e65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Package to Connect to Drive\n","from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Mount to Google Drive\n","drive.mount('/content/drive')\n","\n","# Move to Location, you can change the directory below to move to any location"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667788021243,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"N52qFIv1gxrk","outputId":"24c4854c-0c07-4fc4-c966-7092250474ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SOSCD-paraphrase\n"]}],"source":["%cd /content/drive/Shareddrives/SOSCD-paraphrase/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMvcV-edhI5j"},"outputs":[],"source":["import xml.etree.ElementTree as ET\n","\n","import pandas as pd\n","\n","def read_info(file_name):\n","\txml_data = open(file_name,'r').read()\n","\troot = ET.XML(xml_data)\n","\tdata = []\n","\tfor child in root:\n","\t\tdata.append([subchild.text] for subchild in child)\n","\tdf = pd.DataFrame(data)d\n","\treturn df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1746,"status":"ok","timestamp":1667788022986,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"p3MZ5_dNhzkL","outputId":"eda44a94-fa61-4b21-b686-8637a1b5b04d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ETPC_SQL_v0.95.txt  paraphrase_types.xml  textual_np_pos.xml\n","ETPC_XML_v0.95.txt  text_pairs.xml\t  textual_paraphrases.xml\n","negation.xml\t    textual_np_neg.xml\n"]}],"source":["!ls Corpus/Corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crhv5vjEhvNx"},"outputs":[],"source":["paraphrase_types = read_info('./Corpus/Corpus/paraphrase_types.xml')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1oQFp71h6UI"},"outputs":[],"source":["textual_paraphrases_pos = read_info('./Corpus/Corpus/textual_np_pos.xml')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2dNIcyrjXxU"},"outputs":[],"source":["df = pd.concat([textual_paraphrases_pos[2].apply(lambda x: x[0]), textual_paraphrases_pos[6].apply(lambda x: x[0]), textual_paraphrases_pos[7].apply(lambda x: x[0])], axis = 1)\n","\n","df = df[~((df[6].isnull()) | (df[7].isnull()))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vT67ek3fkGb1"},"outputs":[],"source":["df.columns = ['type', 'sentence1', 'sentence2']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHxQ7_GylBU2"},"outputs":[],"source":["df['sentence1'] = df['sentence1'].str.lower()\n","df['sentence2'] = df['sentence2'].str.lower()\n","df['type'] = df['type'].str.lower()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBa4abGgkojk"},"outputs":[],"source":["df['pairs'] = df['sentence1'] + ' [SEP] ' + df['sentence2']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667398976057,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"RRI3cC8RolH3","outputId":"34a560b1-bbd2-421f-aa44-c782e5c54478"},"outputs":[{"name":"stdout","output_type":"stream","text":["56783\n","66\n","3\n","11.500764320655195\n"]}],"source":["df_word_count = df['pairs']\n","sum = 0 \n","len_list = []\n","for i in range(len(df_word_count)):\n","  sum += len(df_word_count.iloc[i].split())\n","  len_list.append(len(df_word_count.iloc[i].split()))\n","print(sum)\n","print(max(len_list))\n","print(min(len_list))\n","print(np.std(len_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1666887567426,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"zYQSAxRW2POl","outputId":"057a73aa-9a21-41e4-d1fd-7aab0acafd0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["6139\n"]}],"source":["sumlist = [] \n","for i in range(len(df_word_count)):\n","  sumlist += df_word_count.iloc[i].split()\n","print(len(set(sumlist)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2GkMuMzIKiV"},"outputs":[],"source":["annotations_file = open('./annotation.txt','r')\n","df_new = df\n","for eachline in annotations_file:\n","  eachline = eachline.lower()\n","  eachline_split = eachline.split('\\t')\n","  df_new = df_new.append({'type':eachline_split[2][:-1],'sentence1':eachline_split[0],'sentence2':eachline_split[1],'pairs':eachline_split[0]+' [SEP] '+eachline_split[1]}, ignore_index=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230,"status":"ok","timestamp":1667788164637,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"2zIMiDhqysrE","outputId":"4a1120b5-6c09-4505-aba6-2ed0a9d017d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['identity', 'inflectional changes',\n","       'same polarity substitution (contextual)',\n","       'same polarity substitution (habitual)',\n","       'synthetic/analytic substitution', 'change of format',\n","       'change of order', 'subordination and nesting changes',\n","       'same polarity substitution (named ent.)', 'punctuation changes',\n","       'spelling changes', 'syntax/discourse structure changes',\n","       'ellipsis', 'modal verb changes', 'diathesis alternation',\n","       'converse substitution', 'derivational changes', 'entailment',\n","       'coordination changes', 'direct/indirect style alternations',\n","       'addition/deletion', 'sentence modality changes', 'non-paraphrase',\n","       'negation switching', 'opposite polarity substitution (habitual)',\n","       'opposite polarity substitution (contextual)'], dtype=object)"]},"metadata":{},"execution_count":30}],"source":["df['type'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2m4C2IcztED"},"outputs":[],"source":["update = df['type'].isin([\"opposite polarity substitution (contextual)\",\"opposite polarity substitution (habitual)\"])\n","df.loc[update,'type'] = 'opposite polarity substitution'\n","update = df['type'].isin([\"same polarity substitution (contextual)\",\"same polarity substitution (habitual)\", \"same polarity substitution (named ent.)\",\"same polarity substitution (named entities)\"])\n","df.loc[update,'type'] = 'same polarity substitution'\n","update = df['type'].isin([\"modal verb changes\"])\n","df.loc[update,'type'] = 'functional word substitution'\n","update = df['type'].isin([\"semantic based\"])\n","df.loc[update,'type'] = 'relational substitution'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219,"status":"ok","timestamp":1667788169060,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"h6S_5t_85bN3","outputId":"e4c823aa-3e90-4fc8-b3cb-c0d6a5728c68"},"outputs":[{"output_type":"stream","name":"stdout","text":["['identity' 'inflectional changes' 'same polarity substitution'\n"," 'synthetic/analytic substitution' 'change of format' 'change of order'\n"," 'subordination and nesting changes' 'punctuation changes'\n"," 'spelling changes' 'syntax/discourse structure changes' 'ellipsis'\n"," 'functional word substitution' 'diathesis alternation'\n"," 'converse substitution' 'derivational changes' 'entailment'\n"," 'coordination changes' 'direct/indirect style alternations'\n"," 'addition/deletion' 'sentence modality changes' 'non-paraphrase'\n"," 'negation switching' 'opposite polarity substitution']\n","4422\n"]}],"source":["print(df['type'].unique())\n","print(len(df))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1666887583436,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"TgENe8V3O7IW","outputId":"96ae4928-58de-4ed3-a530-56bbeef62506"},"outputs":[{"name":"stdout","output_type":"stream","text":["96865\n","12205\n","279\n","3\n","13.815996118850903\n"]}],"source":["df_new_word_count = df_new['pairs']\n","sum = 0 \n","len_list = []\n","for i in range(len(df_new_word_count)):\n","  Ltem = len(df_new_word_count.iloc[i].split())\n","  sum += Ltem\n","  len_list.append(Ltem)\n","print(sum)\n","\n","sumlist = [] \n","for i in range(len(df_new_word_count)):\n","  sumlist += df_new_word_count.iloc[i].split()\n","print(len(set(sumlist)))\n","\n","print(max(len_list))\n","print(min(len_list))\n","print(np.std(len_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11142,"status":"ok","timestamp":1667788076983,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"ODx3h9vDkzAe","outputId":"d6edd464-2acd-49fd-f663-a0652cf9b4dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 15.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 58.6 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 54.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.24.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9qt3hpDky5R"},"outputs":[],"source":["import torch\n","from sklearn.metrics import f1_score\n","# Creating Dataloader\n","from torch.utils.data import DataLoader, RandomSampler\n","from torch.utils.data import TensorDataset\n","from tqdm.notebook import tqdm\n","from transformers import AutoTokenizer, BertForSequenceClassification\n","\n","# from utils import f1_score_func, evaluate\n","\n","# The Function to Create both Word-level and Character-level Features for BERT\n","def get_name_pair(s):\n","    return s, ' '.join(str(s)).replace('  ', ' ').replace('  ', ' ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2DOfFjNZlMQ9"},"outputs":[],"source":["# Check All Classes\n","possible_labels = df['type'].unique()\n","\n","label_dict = {}\n","for index, possible_label in enumerate(possible_labels):\n","    label_dict[possible_label] = index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCRbsuwvlrKM"},"outputs":[],"source":["df['label'] = df['type'].replace(label_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymJhe4jTlvOo"},"outputs":[],"source":["torch.set_grad_enabled(True)\n","\n","# Store the model we want to use\n","MODEL_NAME = \"bert-base-uncased\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","# Tokenize Data\n","encoded_train = tokenizer.batch_encode_plus(\n","    df['pairs'].values.tolist(),\n","    return_attention_mask=True,\n","    padding=True,\n","    return_tensors='pt')\n","\n","\n","input_ids_train = encoded_train['input_ids']\n","attention_masks_train = encoded_train['attention_mask']\n","labels_train = torch.tensor(df.label.values)\n","\n","# Create datasets\n","dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160,"referenced_widgets":["206fc26ed7c54ffdb0fa13ff8e634fa5","e9bae6cfc9c547a494dce2009864894d","46461d7a374843579536f4497f0ad98d","f7298ab993df4cf88249d7c18ed4ad28","6d38ed1aa61f4bf6bd3caa9b6121468d","00edcb67ca3842859e426361d1045b44","02c955b08ef745048155e7fa612630b4","97b937a2070b41c281386e5324d4cacc","1bd7e689a1574d61bf040c813b14397a","a002b6a70f084888a95dfffbfef4370a","612889f4cc7e4f5dbe5d29d53e8f259f"]},"executionInfo":{"elapsed":9726,"status":"ok","timestamp":1667788195576,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"kRAyocccl2cR","outputId":"e0c947e6-2556-4c4b-dfdd-40fce3a2738e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"206fc26ed7c54ffdb0fa13ff8e634fa5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(label_dict),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)"]},{"cell_type":"markdown","metadata":{"id":"8HyE2ejQnf8i"},"source":["# New Section"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M4owFJAwWUTx"},"outputs":[],"source":["del model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10597,"status":"ok","timestamp":1667094458175,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"az53tt3zTwi1","outputId":"d8c86aaa-cb92-42a6-c42e-d92c2fda863d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Gen RAM Free: 9.8 GB  |     Proc size: 4.8 GB\n","GPU RAM Free: 9197MB | Used: 5912MB | Util  39% | Total     15109MB\n"]}],"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENPJz2APYcBb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Exb0uUZ-nQZZ"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","batch_size = 16\n","k_folds = 5\n","# Define the K-fold Cross Validator\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","\n","dataloader_train = DataLoader(dataset_train,\n","                              #sampler=RandomSampler(dataset_train),\n","                              batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1667491279374,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"WhVmv4hAnQPy","outputId":"bf947da1-762b-4fd3-d661-6d9c31f447a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["from transformers import AdamW\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(),\n","                  lr=1e-4,\n","                  eps=1e-8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kwmxa6jSnQHl"},"outputs":[],"source":["epochs = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjaaP5z_nhwt"},"outputs":[],"source":["import numpy as np\n","import torch\n","from sklearn.metrics import f1_score\n","\n","\n","def f1_score_func(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, preds_flat, average='weighted')\n","\n","# Function to Evaluate Model Performance\n","def evaluate(model, dataloader_val):\n","    model.eval()\n","\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","\n","    for batch in dataloader_val:\n","        batch = tuple(b.cuda() for b in batch)\n","\n","        inputs = {'input_ids': batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels': batch[2],\n","                  }\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","\n","    loss_val_avg = loss_val_total / len(dataloader_val)\n","\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","\n","    return loss_val_avg, predictions, true_vals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNInKEdDnP-W"},"outputs":[],"source":["# Training Model\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset_train)):\n","  # Print\n","  print(f'FOLD {fold}')\n","  print('--------------------------------')\n","\n","  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","  \n","  trainloader = torch.utils.data.DataLoader(\n","                      dataset_train, \n","                      batch_size=16, sampler=train_subsampler)\n","  testloader = torch.utils.data.DataLoader(\n","                      dataset_train,\n","                      batch_size=16, sampler=test_subsampler)\n","\n","  f1_fold = []\n","  f1_score_fold = []\n","  for epoch in tqdm(range(1, epochs + 1)):\n","      model.cuda()\n","      model.train()\n","\n","      loss_train_total = 0\n","\n","      progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False,\n","                          disable=False)\n","      for batch in progress_bar:\n","          model.zero_grad()\n","\n","          batch = tuple(b.cuda() for b in batch)\n","\n","          inputs = {'input_ids': batch[0],\n","                    'attention_mask': batch[1],\n","                    'labels': batch[2],\n","                    }\n","\n","          outputs = model(**inputs)\n","\n","          loss = outputs[0]\n","          loss_train_total += loss.item()\n","          loss.backward()\n","\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          optimizer.step()\n","          progress_bar.set_postfix(\n","              {'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n","\n","      # torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n","\n","      tqdm.write(f'\\nEpoch {epoch}')\n","\n","      loss_train_avg = loss_train_total / len(trainloader)\n","      tqdm.write(f'Training loss: {loss_train_avg}')\n","\n","      val_loss, predictions, true_vals = evaluate(model, testloader)\n","      val_f1 = f1_score_func(predictions, true_vals, )\n","      f1_fold.append(val_f1)\n","      tqdm.write(f'Validation loss: {val_loss}')\n","      tqdm.write(f'F1 Score (Weighted): {val_f1}')\n","\n","  # Model Performance\n","  val_loss, predictions, true_vals = evaluate(model, testloader)\n","  f1_score_fold.append(f1_score(true_vals, np.argmax(predictions, axis=1), average=None))\n","f1_fold_average = torch.mean(torch.Tensor(f1_fold))\n","f1_score_fold_average = torch.mean(torch.Tensor(f1_score_fold))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1667499478686,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"OeFiMawiri0w","outputId":"f64fdad9-9a16-4119-8add-7f876e00d942"},"outputs":[{"data":{"text/plain":["array([0.99478261, 0.91428571, 0.96395194, 0.95412844, 0.92857143,\n","       0.79245283, 0.75862069, 1.        , 0.7826087 , 0.8       ,\n","       0.88888889, 0.92307692, 1.        , 0.47619048, 0.85714286,\n","       0.8       , 0.8       , 0.        , 0.        ])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["f1_score(true_vals, np.argmax(predictions, axis=1), average=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbFekcDbr8Bk"},"outputs":[],"source":["from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667499478687,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"ru-LS8_3r6uP","outputId":"79c22142-09f8-43f9-c8d7-5697ba3ffc0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       286\n","           1       0.97      0.86      0.91        37\n","           2       0.96      0.97      0.96       373\n","           3       0.91      1.00      0.95        52\n","           4       0.87      1.00      0.93        13\n","           5       0.91      0.70      0.79        30\n","           6       0.92      0.65      0.76        17\n","           7       1.00      1.00      1.00        18\n","           8       1.00      0.64      0.78        14\n","           9       0.67      1.00      0.80         4\n","          10       0.89      0.89      0.89         9\n","          11       0.86      1.00      0.92         6\n","          12       1.00      1.00      1.00         2\n","          13       0.31      1.00      0.48         5\n","          14       1.00      0.75      0.86         4\n","          16       0.86      0.75      0.80         8\n","          17       1.00      0.67      0.80         3\n","          20       0.00      0.00      0.00         2\n","          22       0.00      0.00      0.00         1\n","\n","    accuracy                           0.95       884\n","   macro avg       0.80      0.78      0.77       884\n","weighted avg       0.95      0.95      0.95       884\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["print(classification_report(true_vals, np.argmax(predictions, axis=1)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667499478688,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"MVDQ_5ofrj4T","outputId":"5655bf6e-d94e-48bb-82f5-bc150f5bb01a"},"outputs":[{"data":{"text/plain":["{'identity': 0,\n"," 'inflectional changes': 1,\n"," 'same polarity substitution': 2,\n"," 'synthetic/analytic substitution': 3,\n"," 'change of format': 4,\n"," 'change of order': 5,\n"," 'subordination and nesting changes': 6,\n"," 'punctuation changes': 7,\n"," 'spelling changes': 8,\n"," 'syntax/discourse structure changes': 9,\n"," 'ellipsis': 10,\n"," 'functional word substitution': 11,\n"," 'diathesis alternation': 12,\n"," 'converse substitution': 13,\n"," 'derivational changes': 14,\n"," 'entailment': 15,\n"," 'coordination changes': 16,\n"," 'direct/indirect style alternations': 17,\n"," 'addition/deletion': 18,\n"," 'sentence modality changes': 19,\n"," 'non-paraphrase': 20,\n"," 'negation switching': 21,\n"," 'opposite polarity substitution': 22}"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["label_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667499478688,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":240},"id":"frbDimkJrnsG","outputId":"e01af220-43df-4aed-c70e-86fbd843c5dd"},"outputs":[{"data":{"text/plain":["type                              \n","same polarity substitution            1711\n","identity                              1503\n","synthetic/analytic substitution        263\n","inflectional changes                   168\n","change of order                        152\n","punctuation changes                    136\n","subordination and nesting changes       97\n","spelling changes                        67\n","syntax/discourse structure changes      64\n","change of format                        62\n","functional word substitution            37\n","ellipsis                                29\n","derivational changes                    28\n","diathesis alternation                   27\n","coordination changes                    20\n","converse substitution                   16\n","direct/indirect style alternations      16\n","addition/deletion                        7\n","sentence modality changes                5\n","non-paraphrase                           5\n","entailment                               4\n","opposite polarity substitution           3\n","negation switching                       2\n","dtype: int64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df[['type']].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_qFWmfIm7Lw"},"outputs":[],"source":["# torch.save(model.state_dict(), './BERT_paraphrase_5epochs.pt')\n","torch.save(model.state_dict(), './BERT_paraphrase_10epochs.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1667788090780,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"FOlysLsZEyRE","outputId":"117d9221-b793-43de-bcf7-0c115f3b9d5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SOSCD-paraphrase\n"]}],"source":["%cd /content/drive/Shareddrives/SOSCD-paraphrase/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1667788092002,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"u1ffht3vFj3n","outputId":"06fd91da-67f2-4d46-aa77-057826a09530"},"outputs":[{"output_type":"stream","name":"stdout","text":[" annotation.txt                \u001b[0m\u001b[01;34mCorpus\u001b[0m/        sen2.txt\n"," BERT.ipynb                    label          totalsamples\n"," BERT_paraphrase_10epochs.pt   meeting.gdoc  'training data combine.ipynb'\n"," BERT_paraphrase_20epochs.pt   \u001b[01;34msamples\u001b[0m/\n"," BERT_paraphrase_5epochs.pt    sen1.txt\n"]}],"source":["%ls "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lhq4VgWZE6qS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667794627416,"user_tz":300,"elapsed":1238,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"}},"outputId":"c1a1a68d-e013-4c00-a8dc-ff762ab2fe10"},"outputs":[{"output_type":"stream","name":"stdout","text":["7000\n"]}],"source":["import pandas as pd\n","df = pd.read_csv(\"./totalsamples\",sep=\"\\t|\\n\",header=None,names = [\"id\",\"sentence1\",\"sentence2\"])\n","df['sentence1'] = df['sentence1'].astype(str)\n","df['sentence2'] = df['sentence2'].astype(str)\n","df['sentence1'] = df['sentence1'].str.lower()\n","df['sentence2'] = df['sentence2'].str.lower()\n","df['pairs'] = df['sentence1'] + ' [SEP] ' + df['sentence2']\n","print(len(df))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2260,"status":"ok","timestamp":1667794632138,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"B_CKyKbTrby0","outputId":"2aa5e497-5e17-43ed-ab2d-08b0c1a97492"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["torch.set_grad_enabled(False)\n","\n","# Store the model we want to use\n","MODEL_NAME = \"bert-base-uncased\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(label_dict),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uflHtCVXDDd"},"outputs":[],"source":["model.load_state_dict(torch.load('./BERT_paraphrase_10epochs.pt'))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efUb-lYVaasu"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-a2lnUvcY4YM"},"outputs":[],"source":["df['pairs'].values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4PiiUceqXO3b"},"outputs":[],"source":["# Tokenize Data\n","encoded_pre = tokenizer.batch_encode_plus(\n","    df['pairs'].values.tolist(),\n","    return_attention_mask=True,\n","    padding=True,\n","    truncation = True,\n","    return_tensors='pt')\n","\n","input_ids_pre = encoded_pre['input_ids']\n","attention_masks_pre = encoded_pre['attention_mask']\n","labels_pre = torch.tensor([0] * len(df))\n","\n","# Create datasets\n","dataset_pred = TensorDataset(input_ids_pre, attention_masks_pre, labels_pre)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["f9a1e2e91d844aba9323589d1846db18","a77a010e6a134ebc8160f733b9b19e03","9b979804c4ee4f0cbf0c241e26ff00b2","b8c15d9277a144dc9bbec5c82fe8b8dd","fc4512666dc34b44a8d8540098b70f25","75d7bf8ffef44974a60758eb6512f394","ba11033ccf9a48e6b7833fcb501a0252","92d6b000483c4efb94d949a5c455a2cb","c93e22bac7bc4d29bd181f1634dcff4f","f8c088eaa1dd4e45a9cadf6ab1c86edd","566b087b285f4be28b75f5e27ed3f535"]},"executionInfo":{"elapsed":153000,"status":"ok","timestamp":1667794792346,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"},"user_tz":300},"id":"m1eP32ALYPCb","outputId":"f6185cf8-e96f-4cf4-8523-e196e1013fdb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a1e2e91d844aba9323589d1846db18"}},"metadata":{}}],"source":["preloader = torch.utils.data.DataLoader(\n","                    dataset_pred, \n","                    batch_size=1)\n","\n","progress_bar = tqdm(preloader,leave=False,\n","                    disable=False)\n","for batch in progress_bar:\n","    model.cuda()\n","\n","    batch = tuple(b.cuda() for b in batch)\n","\n","    inputs = {'input_ids': batch[0],\n","              'attention_mask': batch[1],\n","              'labels': batch[2],\n","              }\n","    outputs = model(**inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZADu5Y8kZ42I"},"outputs":[],"source":["loss_val_avg, predictions, true_vals =  evaluate(model,preloader)"]},{"cell_type":"code","source":["np.argmax(predictions, axis=1)"],"metadata":{"id":"Tlt-qA_i50Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GlQAsvFaDU6"},"outputs":[],"source":["df['pred'] = [possible_labels[x] for x in np.argmax(predictions, axis=1)]"]},{"cell_type":"code","source":["st,en = 0,999\n","L = len(df)\n","for i in range(0,int(L//1000)):\n","  print(df[['pred']].iloc[(st + 1000 * i):(en + 1000 * i)].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIj6sRSunRpN","executionInfo":{"status":"ok","timestamp":1667794951186,"user_tz":300,"elapsed":13,"user":{"displayName":"Chao Zhou","userId":"04094983015878341145"}},"outputId":"15a94123-ce0b-400b-edf6-bff12d8dbfec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pred                              \n","identity                              771\n","punctuation changes                   126\n","same polarity substitution             61\n","sentence modality changes              11\n","synthetic/analytic substitution        11\n","syntax/discourse structure changes     10\n","functional word substitution            5\n","subordination and nesting changes       2\n","converse substitution                   1\n","ellipsis                                1\n","dtype: int64\n","pred                              \n","identity                              681\n","punctuation changes                   279\n","same polarity substitution             15\n","change of order                         5\n","syntax/discourse structure changes      5\n","converse substitution                   4\n","subordination and nesting changes       3\n","ellipsis                                2\n","change of format                        1\n","coordination changes                    1\n","diathesis alternation                   1\n","sentence modality changes               1\n","synthetic/analytic substitution         1\n","dtype: int64\n","pred                              \n","identity                              909\n","punctuation changes                    19\n","sentence modality changes              17\n","same polarity substitution             14\n","syntax/discourse structure changes     14\n","synthetic/analytic substitution        14\n","functional word substitution           11\n","coordination changes                    1\n","dtype: int64\n","pred                              \n","identity                              663\n","sentence modality changes             138\n","same polarity substitution             66\n","syntax/discourse structure changes     49\n","synthetic/analytic substitution        29\n","functional word substitution           20\n","punctuation changes                    16\n","ellipsis                                7\n","subordination and nesting changes       5\n","opposite polarity substitution          3\n","converse substitution                   2\n","change of format                        1\n","dtype: int64\n","pred                              \n","identity                              970\n","direct/indirect style alternations     13\n","punctuation changes                     7\n","same polarity substitution              3\n","diathesis alternation                   2\n","subordination and nesting changes       2\n","syntax/discourse structure changes      1\n","synthetic/analytic substitution         1\n","dtype: int64\n","pred                              \n","identity                              737\n","punctuation changes                   211\n","same polarity substitution             15\n","synthetic/analytic substitution        13\n","functional word substitution            6\n","sentence modality changes               6\n","syntax/discourse structure changes      4\n","diathesis alternation                   2\n","ellipsis                                2\n","subordination and nesting changes       2\n","change of order                         1\n","dtype: int64\n","pred                              \n","identity                              630\n","punctuation changes                   284\n","syntax/discourse structure changes     27\n","converse substitution                  15\n","ellipsis                               13\n","change of order                         8\n","same polarity substitution              8\n","subordination and nesting changes       7\n","diathesis alternation                   5\n","entailment                              1\n","functional word substitution            1\n","dtype: int64\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"206fc26ed7c54ffdb0fa13ff8e634fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9bae6cfc9c547a494dce2009864894d","IPY_MODEL_46461d7a374843579536f4497f0ad98d","IPY_MODEL_f7298ab993df4cf88249d7c18ed4ad28"],"layout":"IPY_MODEL_6d38ed1aa61f4bf6bd3caa9b6121468d"}},"e9bae6cfc9c547a494dce2009864894d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00edcb67ca3842859e426361d1045b44","placeholder":"​","style":"IPY_MODEL_02c955b08ef745048155e7fa612630b4","value":"Downloading: 100%"}},"46461d7a374843579536f4497f0ad98d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97b937a2070b41c281386e5324d4cacc","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bd7e689a1574d61bf040c813b14397a","value":440473133}},"f7298ab993df4cf88249d7c18ed4ad28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a002b6a70f084888a95dfffbfef4370a","placeholder":"​","style":"IPY_MODEL_612889f4cc7e4f5dbe5d29d53e8f259f","value":" 440M/440M [00:07&lt;00:00, 56.1MB/s]"}},"6d38ed1aa61f4bf6bd3caa9b6121468d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00edcb67ca3842859e426361d1045b44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02c955b08ef745048155e7fa612630b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97b937a2070b41c281386e5324d4cacc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bd7e689a1574d61bf040c813b14397a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a002b6a70f084888a95dfffbfef4370a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"612889f4cc7e4f5dbe5d29d53e8f259f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9a1e2e91d844aba9323589d1846db18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a77a010e6a134ebc8160f733b9b19e03","IPY_MODEL_9b979804c4ee4f0cbf0c241e26ff00b2","IPY_MODEL_b8c15d9277a144dc9bbec5c82fe8b8dd"],"layout":"IPY_MODEL_fc4512666dc34b44a8d8540098b70f25"}},"a77a010e6a134ebc8160f733b9b19e03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75d7bf8ffef44974a60758eb6512f394","placeholder":"​","style":"IPY_MODEL_ba11033ccf9a48e6b7833fcb501a0252","value":"100%"}},"9b979804c4ee4f0cbf0c241e26ff00b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_92d6b000483c4efb94d949a5c455a2cb","max":7000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c93e22bac7bc4d29bd181f1634dcff4f","value":7000}},"b8c15d9277a144dc9bbec5c82fe8b8dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8c088eaa1dd4e45a9cadf6ab1c86edd","placeholder":"​","style":"IPY_MODEL_566b087b285f4be28b75f5e27ed3f535","value":" 7000/7000 [02:33&lt;00:00, 45.05it/s]"}},"fc4512666dc34b44a8d8540098b70f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"75d7bf8ffef44974a60758eb6512f394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba11033ccf9a48e6b7833fcb501a0252":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92d6b000483c4efb94d949a5c455a2cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c93e22bac7bc4d29bd181f1634dcff4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8c088eaa1dd4e45a9cadf6ab1c86edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"566b087b285f4be28b75f5e27ed3f535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}